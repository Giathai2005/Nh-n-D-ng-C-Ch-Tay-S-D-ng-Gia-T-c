import os
import numpy as np
import joblib  # D√πng thay cho sklearn.externals.joblib
from sklearn import svm
from sklearn.model_selection import train_test_split
from scipy.interpolate import interp1d
from tqdm import tqdm  # Th√™m th∆∞ vi·ªán hi·ªÉn th·ªã ti·∫øn tr√¨nh

# === 1. Chu·∫©n b·ªã d·ªØ li·ªáu ===
data_root = "/content/drive/My Drive/data"  # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu
x_data, y_data = [], []
classes = {}
fixed_rows = 50  # S·ªë d√≤ng c·ªë ƒë·ªãnh
num_columns = 16  # S·ªë c·ªôt c·ªë ƒë·ªãnh
fixed_size = fixed_rows * num_columns

# L·∫∑p qua t·∫•t c·∫£ file trong th∆∞ m·ª•c
def load_data_from_folder(folder_path):
    label_index = 0  # G√°n ch·ªâ s·ªë nh√£n b·∫Øt ƒë·∫ßu t·ª´ 0
    files = [f for f in os.listdir(folder_path) if f.endswith(".txt")]
    
    for filename in tqdm(files, desc="ƒêang t·∫£i d·ªØ li·ªáu", unit="file"):
        path = os.path.join(folder_path, filename)
        data = np.loadtxt(path)
        
        # Ki·ªÉm tra s·ªë c·ªôt h·ª£p l·ªá
        if data.shape[1] != num_columns:
            print(f"‚ö†Ô∏è B·ªè qua file {filename} do kh√¥ng ƒë·ªß {num_columns} c·ªôt d·ªØ li·ªáu")
            continue
        
        # X·ª≠ l√Ω n·ªôi suy ho·∫∑c c·∫Øt b·ªõt d·ªØ li·ªáu ƒë·ªÉ c√≥ s·ªë d√≤ng c·ªë ƒë·ªãnh
        current_rows = data.shape[0]
        if current_rows < fixed_rows:
            x_old = np.linspace(0, 1, current_rows)
            x_new = np.linspace(0, 1, fixed_rows)
            data_interp = np.array([interp1d(x_old, data[:, i], fill_value="extrapolate")(x_new) for i in range(num_columns)]).T
        else:
            data_interp = data[:fixed_rows, :]
        
        # Chuy·ªÉn d·ªØ li·ªáu th√†nh m·∫£ng 1D
        flat_data = data_interp.flatten()
        x_data.append(flat_data)  # Th√™m v√†o danh s√°ch
        
        # L·∫•y t√™n file l√†m nh√£n
        category = filename.split(".")[0]  # L·∫•y ph·∫ßn tr∆∞·ªõc ".txt"
        if category not in classes.values():
            classes[label_index] = category
            label_index += 1
        
        label = list(classes.keys())[list(classes.values()).index(category)]
        y_data.append(label)

# ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c ch√≠nh
load_data_from_folder(data_root)

# Chuy·ªÉn th√†nh m·∫£ng NumPy
x_data = np.array(x_data)
y_data = np.array(y_data)

# === 2. Hu·∫•n luy·ªán m√¥ h√¨nh ===
print("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh...")
X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)
clf = svm.SVC(kernel="rbf", C=1, probability=True)
clf.fit(X_train, Y_train)
print("‚úÖ Hu·∫•n luy·ªán xong!")

# L∆∞u m√¥ h√¨nh l√™n Google Drive
model_path = "/content/drive/My Drive/model_123456.pkl"
classes_path = "/content/drive/My Drive/classes_123456.pkl"
joblib.dump(clf, model_path)
joblib.dump(classes, classes_path)
print(f"üéØ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {model_path}")

# === 3. D·ª± ƒëo√°n tr√™n d·ªØ li·ªáu m·∫´u ===
print("üîé Th·ª≠ nghi·ªám d·ª± ƒëo√°n...")
clf = joblib.load(model_path)
classes = joblib.load(classes_path)

# Ch·ªçn m·ªôt file ng·∫´u nhi√™n t·ª´ d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n
sample_file = next(iter(os.listdir(data_root)))
sample_path = os.path.join(data_root, sample_file)
sample = np.loadtxt(sample_path)

if sample.shape[1] != num_columns:
    print(f"‚ö†Ô∏è D·ªØ li·ªáu d·ª± ƒëo√°n {sample_file} kh√¥ng h·ª£p l·ªá (kh√¥ng ƒë·ªß {num_columns} c·ªôt)")
else:
    current_rows = sample.shape[0]
    if current_rows < fixed_rows:
        x_old = np.linspace(0, 1, current_rows)
        x_new = np.linspace(0, 1, fixed_rows)
        sample_interp = np.array([interp1d(x_old, sample[:, i], fill_value="extrapolate")(x_new) for i in range(num_columns)]).T
    else:
        sample_interp = sample[:fixed_rows, :]
    
    sample = sample_interp.flatten().reshape(1, -1)
    prediction = clf.predict(sample)
    predicted_label = classes[prediction[0]]
    
    print(f"D·ª± ƒëo√°n: {predicted_label}")
    print(f"üìÇ File ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ d·ª± ƒëo√°n: {sample_file}")
